{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmod(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmod(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2689414213699951"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmod(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11920292202211755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmod(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933071490757152"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sigmod(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/titanic/train.csv')\n",
    "test = pd.read_csv('../data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1a163f5588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x = 'Sex', y = 'Survived', kind = 'bar', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1a16d34940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x = 'Pclass', y = 'Survived', kind = 'bar', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1a1c242240>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 430.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x = 'Pclass', y = 'Survived', kind = 'bar', hue = 'Sex', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:,['Sex', 'Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.loc[:,['Sex', 'Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Pclass\n",
       "0    male       3\n",
       "1  female       1\n",
       "2  female       3\n",
       "3  female       1\n",
       "4    male       3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns = ['Sex', 'Pclass'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns = ['Sex', 'Pclass'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10496527, 0.58537091, 0.24906911, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.58537091, 0.24906911, 0.58537091, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.88704025, 0.24906911, 0.88704025,\n",
       "       0.79971453, 0.24906911, 0.10496527, 0.58537091, 0.58537091,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.39478666, 0.88704025,\n",
       "       0.10496527, 0.88704025, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.24906911, 0.24906911, 0.58537091, 0.58537091, 0.39478666,\n",
       "       0.10496527, 0.58537091, 0.58537091, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.79971453, 0.88704025,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.88704025, 0.58537091,\n",
       "       0.39478666, 0.24906911, 0.79971453, 0.88704025, 0.24906911,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.88704025,\n",
       "       0.10496527, 0.24906911, 0.10496527, 0.58537091, 0.39478666,\n",
       "       0.79971453, 0.58537091, 0.39478666, 0.39478666, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.39478666, 0.88704025,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.24906911, 0.58537091,\n",
       "       0.10496527, 0.39478666, 0.39478666, 0.10496527, 0.24906911,\n",
       "       0.10496527, 0.58537091, 0.58537091, 0.58537091, 0.24906911,\n",
       "       0.58537091, 0.10496527, 0.88704025, 0.10496527, 0.39478666,\n",
       "       0.10496527, 0.88704025, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.88704025, 0.24906911, 0.10496527, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.24906911,\n",
       "       0.24906911, 0.58537091, 0.88704025, 0.58537091, 0.88704025,\n",
       "       0.10496527, 0.10496527, 0.58537091, 0.39478666, 0.79971453,\n",
       "       0.79971453, 0.10496527, 0.88704025, 0.10496527, 0.10496527,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.24906911, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.58537091, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.58537091, 0.10496527,\n",
       "       0.58537091, 0.88704025, 0.39478666, 0.24906911, 0.39478666,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.39478666, 0.24906911,\n",
       "       0.88704025, 0.10496527, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.10496527, 0.88704025, 0.58537091, 0.39478666, 0.58537091,\n",
       "       0.58537091, 0.10496527, 0.79971453, 0.10496527, 0.24906911,\n",
       "       0.58537091, 0.39478666, 0.10496527, 0.88704025, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.10496527,\n",
       "       0.79971453, 0.79971453, 0.39478666, 0.79971453, 0.88704025,\n",
       "       0.24906911, 0.39478666, 0.88704025, 0.10496527, 0.88704025,\n",
       "       0.24906911, 0.79971453, 0.10496527, 0.58537091, 0.24906911,\n",
       "       0.24906911, 0.39478666, 0.10496527, 0.24906911, 0.24906911,\n",
       "       0.10496527, 0.39478666, 0.58537091, 0.24906911, 0.58537091,\n",
       "       0.58537091, 0.10496527, 0.39478666, 0.79971453, 0.24906911,\n",
       "       0.39478666, 0.58537091, 0.24906911, 0.88704025, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.79971453, 0.58537091,\n",
       "       0.39478666, 0.58537091, 0.39478666, 0.88704025, 0.10496527,\n",
       "       0.79971453, 0.10496527, 0.79971453, 0.10496527, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.10496527, 0.24906911,\n",
       "       0.24906911, 0.88704025, 0.10496527, 0.10496527, 0.39478666,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.79971453, 0.88704025,\n",
       "       0.88704025, 0.79971453, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.79971453, 0.24906911, 0.79971453, 0.58537091,\n",
       "       0.79971453, 0.10496527, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.79971453, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.79971453, 0.58537091, 0.24906911,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.58537091, 0.10496527,\n",
       "       0.79971453, 0.24906911, 0.24906911, 0.24906911, 0.24906911,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.58537091, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.58537091, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.79971453, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.24906911, 0.24906911, 0.10496527, 0.58537091,\n",
       "       0.88704025, 0.39478666, 0.10496527, 0.39478666, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.58537091, 0.88704025,\n",
       "       0.58537091, 0.39478666, 0.24906911, 0.10496527, 0.24906911,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.39478666, 0.88704025,\n",
       "       0.10496527, 0.79971453, 0.39478666, 0.24906911, 0.24906911,\n",
       "       0.79971453, 0.39478666, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.39478666, 0.24906911, 0.10496527, 0.24906911, 0.10496527,\n",
       "       0.24906911, 0.10496527, 0.10496527, 0.88704025, 0.10496527,\n",
       "       0.58537091, 0.24906911, 0.58537091, 0.24906911, 0.79971453,\n",
       "       0.88704025, 0.24906911, 0.24906911, 0.24906911, 0.58537091,\n",
       "       0.39478666, 0.88704025, 0.10496527, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.79971453, 0.79971453, 0.10496527, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.88704025, 0.24906911,\n",
       "       0.24906911, 0.88704025, 0.39478666, 0.24906911, 0.88704025,\n",
       "       0.88704025, 0.58537091, 0.24906911, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.58537091, 0.58537091, 0.24906911,\n",
       "       0.79971453, 0.10496527, 0.24906911, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.88704025, 0.10496527, 0.24906911, 0.10496527,\n",
       "       0.88704025, 0.10496527, 0.88704025, 0.10496527, 0.10496527,\n",
       "       0.88704025, 0.24906911, 0.88704025, 0.39478666, 0.39478666,\n",
       "       0.24906911, 0.24906911, 0.39478666, 0.58537091, 0.58537091,\n",
       "       0.58537091, 0.88704025, 0.58537091, 0.10496527, 0.88704025,\n",
       "       0.10496527, 0.10496527, 0.10496527])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)[:,1] # some will survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06085883])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.48809433, -0.67634771, -1.7159975 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame({\n",
    "    'Variable:': X_train.columns,\n",
    "    'Weight' : logreg.coef_[0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable:</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>-2.488094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>-0.676348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-1.715997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable:    Weight\n",
       "0  Sex_male -2.488094\n",
       "1  Pclass_2 -0.676348\n",
       "2  Pclass_3 -1.715997"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.48809433, -0.67634771, -1.7159975 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.48809433],\n",
       "       [-0.67634771],\n",
       "       [-1.7159975 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = X_train.dot(logreg.coef_.T) + logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -2.143233\n",
       "1    2.060859\n",
       "2    0.344861\n",
       "3    2.060859\n",
       "4   -2.143233\n",
       "5   -2.143233\n",
       "6   -0.427235\n",
       "7   -2.143233\n",
       "8    0.344861\n",
       "9    1.384511\n",
       "10   0.344861\n",
       "11   2.060859\n",
       "12  -2.143233\n",
       "13  -2.143233\n",
       "14   0.344861\n",
       "15   1.384511\n",
       "16  -2.143233\n",
       "17  -1.103583\n",
       "18   0.344861\n",
       "19   0.344861\n",
       "20  -1.103583\n",
       "21  -1.103583\n",
       "22   0.344861\n",
       "23  -0.427235\n",
       "24   0.344861\n",
       "25   0.344861\n",
       "26  -2.143233\n",
       "27  -0.427235\n",
       "28   0.344861\n",
       "29  -2.143233\n",
       "..        ...\n",
       "861 -1.103583\n",
       "862  2.060859\n",
       "863  0.344861\n",
       "864 -1.103583\n",
       "865  1.384511\n",
       "866  1.384511\n",
       "867 -0.427235\n",
       "868 -2.143233\n",
       "869 -2.143233\n",
       "870 -2.143233\n",
       "871  2.060859\n",
       "872 -0.427235\n",
       "873 -2.143233\n",
       "874  1.384511\n",
       "875  0.344861\n",
       "876 -2.143233\n",
       "877 -2.143233\n",
       "878 -2.143233\n",
       "879  2.060859\n",
       "880  1.384511\n",
       "881 -2.143233\n",
       "882  0.344861\n",
       "883 -1.103583\n",
       "884 -2.143233\n",
       "885  0.344861\n",
       "886 -1.103583\n",
       "887  2.060859\n",
       "888  0.344861\n",
       "889 -0.427235\n",
       "890 -2.143233\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.104965\n",
       "1    0.887040\n",
       "2    0.585371\n",
       "3    0.887040\n",
       "4    0.104965\n",
       "5    0.104965\n",
       "6    0.394787\n",
       "7    0.104965\n",
       "8    0.585371\n",
       "9    0.799715\n",
       "10   0.585371\n",
       "11   0.887040\n",
       "12   0.104965\n",
       "13   0.104965\n",
       "14   0.585371\n",
       "15   0.799715\n",
       "16   0.104965\n",
       "17   0.249069\n",
       "18   0.585371\n",
       "19   0.585371\n",
       "20   0.249069\n",
       "21   0.249069\n",
       "22   0.585371\n",
       "23   0.394787\n",
       "24   0.585371\n",
       "25   0.585371\n",
       "26   0.104965\n",
       "27   0.394787\n",
       "28   0.585371\n",
       "29   0.104965\n",
       "..        ...\n",
       "861  0.249069\n",
       "862  0.887040\n",
       "863  0.585371\n",
       "864  0.249069\n",
       "865  0.799715\n",
       "866  0.799715\n",
       "867  0.394787\n",
       "868  0.104965\n",
       "869  0.104965\n",
       "870  0.104965\n",
       "871  0.887040\n",
       "872  0.394787\n",
       "873  0.104965\n",
       "874  0.799715\n",
       "875  0.585371\n",
       "876  0.104965\n",
       "877  0.104965\n",
       "878  0.104965\n",
       "879  0.887040\n",
       "880  0.799715\n",
       "881  0.104965\n",
       "882  0.585371\n",
       "883  0.249069\n",
       "884  0.104965\n",
       "885  0.585371\n",
       "886  0.249069\n",
       "887  0.887040\n",
       "888  0.585371\n",
       "889  0.394787\n",
       "890  0.104965\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmod(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_predictions = pd.DataFrame({\n",
    "    'PassengerId': test.PassengerId,\n",
    "    'Survived': preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/wzhang/GeneralAssembly/DAT-06-24/class material/Unit 3/Lesson 14'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_predictions.to_csv('/Users/wzhang/GeneralAssembly/DAT-06-24/class material/Unit 3/Lesson 15/titanic/submission.csv',\n",
    "                     index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## method 2: random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72860494, 0.02583214, 0.24556293])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'Features': X_train.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "    \n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.728605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.025832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.245563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  Importance\n",
       "0  Sex_male    0.728605\n",
       "1  Pclass_2    0.025832\n",
       "2  Pclass_3    0.245563"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_submissions = pd.DataFrame({\n",
    "    'PassengerId': test.PassengerId,\n",
    "    'Survived': rf_preds\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_submissions.to_csv('/Users/wzhang/GeneralAssembly/DAT-06-24/class material/Unit 3/Lesson 15/titanic/rf_submission.csv',\n",
    "                     index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'min_samples_leaf': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'n_estimators':[1, 5, 10, 25, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(estimator = rf, param_grid = rf_param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_samples_leaf': [0.1, 0.2, 0.3, 0.4, 0.5], 'n_estimators': [1, 5, 10, 25, 50, 100], 'max_features': ['auto', 'sqrt', 'log2', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_leaf': 0.2, 'n_estimators': 25}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C':[.0001, .001, .01, 1, 10, 100, 1000, 10000] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator = logreg, param_grid = param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 1, 10, 100, 1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "grid_results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.002074      0.000287         0.000843        0.000076  0.0001   \n",
       "1       0.002002      0.000210         0.000839        0.000090  0.0001   \n",
       "2       0.001649      0.000037         0.000762        0.000002   0.001   \n",
       "3       0.001847      0.000198         0.000775        0.000042   0.001   \n",
       "4       0.001735      0.000128         0.000767        0.000022    0.01   \n",
       "\n",
       "  param_penalty                          params  split0_test_score  \\\n",
       "0            l1  {'C': 0.0001, 'penalty': 'l1'}           0.611111   \n",
       "1            l2  {'C': 0.0001, 'penalty': 'l2'}           0.611111   \n",
       "2            l1   {'C': 0.001, 'penalty': 'l1'}           0.611111   \n",
       "3            l2   {'C': 0.001, 'penalty': 'l2'}           0.611111   \n",
       "4            l1    {'C': 0.01, 'penalty': 'l1'}           0.611111   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  split2_train_score  \\\n",
       "0           0.611111           0.617978  ...             0.61596   \n",
       "1           0.611111           0.617978  ...             0.61596   \n",
       "2           0.611111           0.617978  ...             0.61596   \n",
       "3           0.611111           0.617978  ...             0.61596   \n",
       "4           0.611111           0.617978  ...             0.61596   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.61596             0.61596             0.61596   \n",
       "1             0.61596             0.61596             0.61596   \n",
       "2             0.61596             0.61596             0.61596   \n",
       "3             0.61596             0.61596             0.61596   \n",
       "4             0.61596             0.61596             0.61596   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0             0.61596             0.61596             0.61596   \n",
       "1             0.61596             0.61596             0.61596   \n",
       "2             0.61596             0.61596             0.61596   \n",
       "3             0.61596             0.61596             0.61596   \n",
       "4             0.61596             0.61596             0.61596   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  \n",
       "0            0.616438          0.616162         0.000317  \n",
       "1            0.616438          0.616162         0.000317  \n",
       "2            0.616438          0.616162         0.000317  \n",
       "3            0.616438          0.616162         0.000317  \n",
       "4            0.616438          0.616162         0.000317  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_C', 'param_penalty', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
       "       'split4_test_score', 'split5_test_score', 'split6_test_score',\n",
       "       'split7_test_score', 'split8_test_score', 'split9_test_score',\n",
       "       'mean_test_score', 'std_test_score', 'rank_test_score',\n",
       "       'split0_train_score', 'split1_train_score', 'split2_train_score',\n",
       "       'split3_train_score', 'split4_train_score', 'split5_train_score',\n",
       "       'split6_train_score', 'split7_train_score', 'split8_train_score',\n",
       "       'split9_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['param_C', 'param_penalty', 'mean_test_score', 'std_test_score', \n",
    "        'rank_test_score','mean_train_score','std_train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_2 = grid_results.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_penalty  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0  0.0001            l1         0.616162        0.002844               12   \n",
       "1  0.0001            l2         0.616162        0.002844               12   \n",
       "2   0.001            l1         0.616162        0.002844               12   \n",
       "3   0.001            l2         0.616162        0.002844               12   \n",
       "4    0.01            l1         0.616162        0.002844               12   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.616162         0.000317  \n",
       "1          0.616162         0.000317  \n",
       "2          0.616162         0.000317  \n",
       "3          0.616162         0.000317  \n",
       "4          0.616162         0.000317  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.033685</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786758</td>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_penalty  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0   0.0001            l1         0.616162        0.002844               12   \n",
       "1   0.0001            l2         0.616162        0.002844               12   \n",
       "2    0.001            l1         0.616162        0.002844               12   \n",
       "3    0.001            l2         0.616162        0.002844               12   \n",
       "4     0.01            l1         0.616162        0.002844               12   \n",
       "5     0.01            l2         0.786756        0.033685                1   \n",
       "6        1            l1         0.786756        0.027926                1   \n",
       "7        1            l2         0.786756        0.027926                1   \n",
       "8       10            l1         0.786756        0.027926                1   \n",
       "9       10            l2         0.786756        0.027926                1   \n",
       "10     100            l1         0.786756        0.027926                1   \n",
       "11     100            l2         0.786756        0.027926                1   \n",
       "12    1000            l1         0.786756        0.027926                1   \n",
       "13    1000            l2         0.786756        0.027926                1   \n",
       "14   10000            l1         0.786756        0.027926                1   \n",
       "15   10000            l2         0.786756        0.027926                1   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.616162         0.000317  \n",
       "1           0.616162         0.000317  \n",
       "2           0.616162         0.000317  \n",
       "3           0.616162         0.000317  \n",
       "4           0.616162         0.000317  \n",
       "5           0.786758         0.003748  \n",
       "6           0.786756         0.003101  \n",
       "7           0.786756         0.003101  \n",
       "8           0.786756         0.003101  \n",
       "9           0.786756         0.003101  \n",
       "10          0.786756         0.003101  \n",
       "11          0.786756         0.003101  \n",
       "12          0.786756         0.003101  \n",
       "13          0.786756         0.003101  \n",
       "14          0.786756         0.003101  \n",
       "15          0.786756         0.003101  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_2  # the rank is based on mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.033685</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786758</td>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.027926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>12</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_penalty  mean_test_score  std_test_score  rank_test_score  \\\n",
       "5     0.01            l2         0.786756        0.033685                1   \n",
       "6        1            l1         0.786756        0.027926                1   \n",
       "7        1            l2         0.786756        0.027926                1   \n",
       "8       10            l1         0.786756        0.027926                1   \n",
       "9       10            l2         0.786756        0.027926                1   \n",
       "10     100            l1         0.786756        0.027926                1   \n",
       "11     100            l2         0.786756        0.027926                1   \n",
       "12    1000            l1         0.786756        0.027926                1   \n",
       "13    1000            l2         0.786756        0.027926                1   \n",
       "14   10000            l1         0.786756        0.027926                1   \n",
       "15   10000            l2         0.786756        0.027926                1   \n",
       "0   0.0001            l1         0.616162        0.002844               12   \n",
       "1   0.0001            l2         0.616162        0.002844               12   \n",
       "2    0.001            l1         0.616162        0.002844               12   \n",
       "3    0.001            l2         0.616162        0.002844               12   \n",
       "4     0.01            l1         0.616162        0.002844               12   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "5           0.786758         0.003748  \n",
       "6           0.786756         0.003101  \n",
       "7           0.786756         0.003101  \n",
       "8           0.786756         0.003101  \n",
       "9           0.786756         0.003101  \n",
       "10          0.786756         0.003101  \n",
       "11          0.786756         0.003101  \n",
       "12          0.786756         0.003101  \n",
       "13          0.786756         0.003101  \n",
       "14          0.786756         0.003101  \n",
       "15          0.786756         0.003101  \n",
       "0           0.616162         0.000317  \n",
       "1           0.616162         0.000317  \n",
       "2           0.616162         0.000317  \n",
       "3           0.616162         0.000317  \n",
       "4           0.616162         0.000317  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_2.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
